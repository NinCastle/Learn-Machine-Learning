{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/2017/03/08/CNN_Getting_Started/)  \n",
    "하기 내용은 상기 링크를 정리한것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 정의하기\n",
    "손그림인 삼각형, 사각형, 원을 그려 이미지로 저장한 다음 이른 분류하는 모델을 생성한다.  \n",
    "문제 형태와 입출력을 다음과 같이 정의한다.  \n",
    "* 문제 형태 : 다중 클래스 분류\n",
    "* 입력 : 손으로 그린 삼각형, 사각형, 원 이미지\n",
    "* 출력 : 삼각형, 사각형, 원일 확률을 나타내는 벡터  \n",
    "  \n",
    "가장 처음 필요한 패키지를 불러오고, 매번 실행 시마다 결과가 달라지지 않도록 랜덤 시드를 명시적으로 지정한다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비하기\n",
    "손으로 그린 삼각형, 사각형 원 이미지를 만들기 위해서는 여러가지 방법이 있을수 있다.  \n",
    "테블릿을 이용할 수도 있고, 종이에 그려 사진으로 찍을 수 있다.  \n",
    "그림 이미지 사이즈는 그리는 툴로 $24 \\times 24$ 정도로 해봤다.\n",
    "![](http://tykimos.github.io/warehouse/2017-3-8_CNN_Getting_Started_1.png)\n",
    "모양별로 20개 정도를 만들어서 15개를 훈련에 사용하고, 5개를 테스트에 사용해본다.  \n",
    "이미지는 png나 jpg로 저장한다.  \n",
    "실제로 데이터셋이 어떻게 구성되어 있는지 모른 체 튜토리얼을 따라하거나,  \n",
    "예제 코드를 실행시키다보면 결과는 잘 나오지만 막상 실제 문제에 적용할때는 막막할 때가 많다.  \n",
    "간단한 예제로 직접 데이터셋을 만들어봄으로써 실제 문제에 접근할 때 시행착오를 줄이는 것이 중요하다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 폴더는 다음과 같이 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train\n",
    "    * circle\n",
    "    * rectangle\n",
    "    * triangle\n",
    "* test\n",
    "    * circle\n",
    "    * rectangle\n",
    "    * traingle  \n",
    "      \n",
    "![](http://tykimos.github.io/warehouse/2017-3-8_CNN_Getting_Started_2.png)  \n",
    "아래의 링크를 이용하여 다운로드가 가능하다.  \n",
    "http://tykimos.github.io/warehouse/2017-3-8_CNN_Getting_Started_handwriting_shape.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 생성하기\n",
    "케라스에서는 이미지 파일을 쉽게 학습시킬 수 있도록 ImangeDataGenerator 클래스를 제공한다.  \n",
    "ImageDataGenerator클래스는 데이터 증강 (data augmentation)을 위해 막강한 기능을 제공하는데,  \n",
    "이 기능들은 다른 곳에서 다루고,  \n",
    "이 곳에서는 특정 폴더에 이미지를 분류 해 놓았을 때 이를 학습시키기 위한 데이터셋으로 만들어주는 기능을 사용해보겠다.    \n",
    "먼저 ImageDataGenerator클래스를 이용하여 객체를 생성한 뒤  \n",
    "flow_from_directory() 함수를 호출하여 제네레이터(generator)를 생성한다.  \n",
    "flow_from_directory() 함수의 주요인자는 다음과 같다.  \n",
    "* 첫번째 인자 : 이미지 경로를 지정한다.\n",
    "* target_size : 패치 이미지 크기를 지정한다.  \n",
    "폴더에 있는 원본 이미지 크기가 다르더라도 target_size에 지정된 크기로 자동 조절된다.\n",
    "* batch_size : 배치 크기를 지정한다.\n",
    "* class_mode : 분류 방식에 대해서 지정한다. \n",
    "    * categorical : 2D one-hot 부호화된 라벨이 반환된다.\n",
    "    * binary : 1D 이진 라벨이 반환된다. \n",
    "    * sparse : 1D 정수 라벨이 반환된다.\n",
    "    * None : 라벨이 반환되지 않는다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 예제에서는 패치 이미지 크기를 $24 \\times 24$로 하였으니 target_size도 (24, 24)로 셋팅하였다.  \n",
    "훈련 데이터 수가 클래스당 15개이니   \n",
    "배치 크기를 3으로 지정하여(가중치 업데이트)   \n",
    "총 5번 배치를 수행하면 하나의 epoch가 수행될 수 있도록 하였다.   \n",
    "다중 클래스 문제이므로 class_mode는 'categorical'로 지정하였다.  \n",
    "그리고 제네레이터는 훈련용과 검증용으로 두 개를 만들었다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './handwriting_shape/train',\n",
    "    target_size=(24, 24),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './handwriting_shape/test',\n",
    "    target_size=(24, 24),\n",
    "    batch_size=3, \n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성하기\n",
    "영상 분류에 높은 성능을 보이고 있는 컨볼루션 신경망 모델을 구성해본다.  \n",
    "각 레이어들은 이전 강좌에서 살표보았으므로 크게 어려움없이 구성할 수 있다.  \n",
    "    * 컨볼루션 레이어 : 입력 이미지 크기 $24 \\times 24$, 입력 이미지 채널 3개, 필터 크기 $3 \\times 3$, 필터 수 32개, 활성화 함수 'relu'\n",
    "    * 컨볼루션 레이어 : 필터 크기 $3 \\times 3$, 필터 수 64개, 활성화 함수 'relu'\n",
    "    * 맥스풀링 레이어 : 풀 크기 $2 \\times 2$\n",
    "    * 플래튼 레이어(벡터화)\n",
    "    * 댄스 레이어 : 출력 뉴런 수 128개, 활성화 함수 'relu'\n",
    "    * 댄스 레이어 : 출력 뉴런 수 3개, 활성화 함수 'sotfmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(24, 24, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구성화한 모델을 가시화하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Ipython'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f2ebb8674c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mIpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Ipython'"
     ]
    }
   ],
   "source": [
    "from Ipython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습과정 설정하기\n",
    "모델을 정의했다면 모델을 손실함수와 최적화 알고리즘으로 엮는다.  \n",
    "* loss : 현재 가중치 세트를 평가하는데 사용한 손실 함수이다.  \n",
    "다중 클래스 문제이므로 'categorical_crossentropy'으로 지정한다.  \n",
    "* optimizer : 최적의 가중치를 검색하는 데 사용되는 최적화 알고리즘으로 효율적인 경사 하강법 알고리즘 중 하나인 'adam'을 사용한다.  \n",
    "* metrics : 평가 척도를 나타내며 분류 문제에서는 일반적으로 'accuracy'으로 지정한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습시키기\n",
    "케라스에서는 모델을 학습시킬 때 주로 fit() 함수를 사용하지만 제네레이터로 생성 된 배치로 학습시킬 경우에는 fit_generator()함수를 사용한다.  \n",
    "본 예제는 ImageDataGenerator라는 제네레이터로 이미지를 담고 있는 배치로 학습시키기 때문에 fit_generator()함수를 사용한다.    \n",
    "* 첫번째 인자 : 훈련데이터셋을 제공할 제네레이터를 지정한다.  \n",
    "본 예제에서는 앞서 생성한 train_generator으로 지정한다.  <br>\n",
    "<br>\n",
    "* steps_per_epoch : 한 epoch에 사용한 스텝 수를 지정한다.  \n",
    "총 45개의 훈련 샘플이 있고 배치 사이즈가 3이므로 15 스텝으로 지정한다.  <br>\n",
    "<br>\n",
    "* epochs: 전체 훈련 데이터 셋에 대해 학습 반복 횟수를 지정한다.  \n",
    "100번을 반복적으로 학습시켜본다.  <br>\n",
    "<br>\n",
    "\n",
    "* validation_data : 검증데이터셋을 제공할 제네레이터를 지정한다.  \n",
    "본 예제에서는 앞서 생성한 validation_generator으로 지정한다.  <br>\n",
    "<br>\n",
    "* validation_steps :  한 epoch 종료 시 마다 검증할 떄 사용되는 검증 스텝 수를 지정한다.  \n",
    "총 15개의 검증 샘플(test 이미지 개수)이 있고 배치사이즈가 3이므로 5스텝으로 지정한다.  <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 120s 8s/step - loss: 1.1965 - acc: 0.5556 - val_loss: 0.7390 - val_acc: 0.6667\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5381 - acc: 0.7556 - val_loss: 0.3682 - val_acc: 0.9333\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1749 - acc: 0.9556 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0503 - acc: 0.9778 - val_loss: 0.1048 - val_acc: 0.9333\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 7.0594e-04 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 5.2183e-04 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.9572e-04 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.0335e-04 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.4689e-04 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.0469e-04 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.7437e-04 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.5522e-04 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2816e-04 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.1241e-04 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 9.7316e-05 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 8.6082e-05 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 7.5463e-05 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.7834e-05 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 6.1806e-05 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 5.4865e-05 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.0524e-05 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 4.4825e-05 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 4.0187e-05 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 3.5665e-05 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 3.3133e-05 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.0281e-05 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.7848e-05 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.5438e-05 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.3505e-05 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.1848e-05 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.0607e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.8979e-05 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.7726e-05 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6085e-05 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.4863e-05 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3501e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.2474e-05 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.1545e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0794e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0096e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 9.5210e-06 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 8.9289e-06 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 8.7236e-06 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 8.0335e-06 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 7.6043e-06 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 7.1738e-06 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.8506e-06 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a0ddfdca58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=15,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기\n",
    "학습한 모델을 평가해본다.  \n",
    "제네레이터에서 제공되는 샘플로 평가할 때는 evaluate_generator함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluate ---\n",
      "acc: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Evaluate ---\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"{}: {}%\".format(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 적고 간단한 모델임에도 100%라는 높은 정확도를 얻었다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 사용하기\n",
    "모델 사용 시에 제네레이터에서 제공되는 샘플을 입력할 때는 predict_generator함수를 사용한다.  \n",
    "예측 결과는 클래스별 확률 벡터로 출력되며,  \n",
    "클래스에 해당하는 열을 알기 위해서는 제네레이터의 'class_indices'를 출력하면 해당 열의 클래스 명을 알려준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Predict ---\n",
      "{'circle': 0, 'rectangle': 1, 'triangle': 2}\n",
      "[[0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.099 0.889 0.012]\n",
      " [0.000 1.000 0.000]\n",
      " [0.987 0.000 0.013]\n",
      " [0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.001 0.999]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Predict ---\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './handwriting_shape/train',\n",
    "    target_size=(24, 24),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './handwriting_shape/test',\n",
    "    target_size=(24, 24),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), \n",
    "                activation='relu',\n",
    "                input_shape=(24, 24, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 모델학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.8092 - acc: 0.6889 - val_loss: 0.3883 - val_acc: 0.9333\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1185 - acc: 0.9778 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.2191e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.4511e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.5563e-04 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2333e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 9.5345e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 7.8832e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 6.4739e-05 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.6237e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 4.9847e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 4.1648e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.6315e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 3.3007e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.8462e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.5687e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.2810e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.1337e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.8739e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.7249e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.5794e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.4454e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3446e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.2480e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.1254e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0538e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 9.8919e-06 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 9.0057e-06 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 8.5554e-06 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 8.0706e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 7.4215e-06 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 6.9487e-06 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 6.6162e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 6.2254e-06 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.8466e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.5631e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 5.2095e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 4.9949e-06 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 4.6982e-06 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 4.4571e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 4.2359e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 4.0293e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 3.8187e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.6386e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.4478e-06 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.2942e-06 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.1273e-06 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.9405e-06 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a07000d6a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=15,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "acc: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"{}: {}%\".format(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Predict --\n",
      "{'circle': 0, 'rectangle': 1, 'triangle': 2}\n",
      "[[0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.001 0.999]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.075 0.916 0.009]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.999 0.000 0.001]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]]\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x : \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "이미지 분류 문제에 높은 성능을 보이고 있는 컨볼루션 신경망 모델을 이용하여 직접 만든 데이터 셋으로 학습 평가를 해보았다.  \n",
    "학습결과는 좋게 나왔지만 이 모델은 한사람이 그린 것에 대해서만 학습이 되어 다른 사람이 그린 모양은 분류를 잘못한다.  \n",
    "이를 해결하기 위한 방안으로 '데이터 부풀리기' 기법이있다.  <br>\n",
    "<br>\n",
    "참고로 실제 문제에 적용하기 전에 데이터셋을 직접 만들어보거나 좀더 쉬운 문제로 추상화해서 프로토 타이핑 하는 것을 추천한다.  \n",
    "객담도말된 결핵 이미지를 판별하는 모델을 만들 때,  \n",
    "결핵 이미지를 바로 사용하지 않고,  \n",
    "MNIST의 손글씨 중 '1', '7'을 결핵이라고 보고, 나머지는 결핵이 아닌 것으로 학습시켜봤었다.  \n",
    "결핵균이 간균(막대모양)이라 적절한 프로토 타이핑이었고,  \n",
    "타이핑 모델과 실제 데이터셋으로 학습한 모델 결과가 크게 차이나지 않는다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
