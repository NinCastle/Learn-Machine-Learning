{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[인투더데이터](http://intothedata.com/02.scholar_category/anomaly_detection/)  \n",
    "[대소니 - 이상감지 Anomaly Detection System 개요](http://daeson.tistory.com/216)  \n",
    "[대소니 - 이상감지 Anomaly Detection System 만들기](http://daeson.tistory.com/217?category=654766)  \n",
    "[대소니 - 이상감지 Anomaly Detection System 그외 알고리즘](http://daeson.tistory.com/218?category=654766)  \n",
    "[Anomaly Detection, a short tutorial using Python](https://aqibsaeed.github.io/2016-07-17-anomaly-detection/)  \n",
    "하기 내용은 상기 링크들을 정리한것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정상치에서 벗어난 관측치들을 detect하는것. \n",
    "또는 미래에 이상한 상태로 진입될 여지가 있는 것을 미리 찾는것.\n",
    "One-class classification OR one-class description이라고 부르기도 한다.\n",
    "기술적으로 잘 알려진 몇개의 알고리즘으로 단순하게 알고리즘을 사용하는 사용자의 관점에서는 현실에서 주어지는 문제를 해결하기에는 어렵고,  \n",
    "분야 전문가(Domain Expert)의 통찰을 얻어서 그것을 찾기 위한 감지 모델을 직접 여러 알고리즘을 이용하여 구현하거나,  아니면 스스로 규칙을 찾아내고 찾을 수 있는 방법을 고안해야한다.  \n",
    "이상감지라는 것이 단순히 생각하면 이상값을 찾는것이지만 실현에 옮기가 매우 어려운 경우가 현실적으로는 많다.   \n",
    "<br>\n",
    "<br>\n",
    "## 진행요령\n",
    "이상감지의 목표는 이상감지를 위해 \"이상하지 않은 것\" 즉 평범한 것(normal)부터 정의해야한다.  \n",
    "당연한 것이지만 이것부터 정의 되지 않으면 하기 어렵다.  \n",
    "이후 \"이상한 것\"을 정의하고 그것을 찾는 모형(model)를 만들거나 적합한 것을 찾는다.  \n",
    "<br>\n",
    "<br>\n",
    "## 특징\n",
    "이상징후의 문제는 데이터분석, 데이터 마이닝 보다 데이터 전처리 단계에서 수행해야 할 항목이 많으며 연상량도 비교적 많다.  \n",
    "보통 실제문제에서는 학습데이터(training set)를 사용할 수 없는 경우가 많아 분류(classification)모델을 만들 수가 없는 경우가 대부분인데 이를 위한 방법들을 말하며 이상한 것에 대한 샘플이 없기 떄문에 사실상 이상치를 정확히 찾아내기 어렵다.  \n",
    "<br>\n",
    "하지만 대략 예측하지 못했던 노이즈나 중심값에서 벗어난 데이터들을 찾아내고 조합시켜서 인사이트를 도출하는데 유요하며 비즈니스에 대한 이해도가 높은 경우 결과물의 활용도가 매우 높아질 수 있다.  \n",
    "학습데이터가 없으므로 이상한 것(anomaly)을 찾기전에 이상하지 않은 것(nomal)이 무엇인지를 정의하는 것이 먼저 해결해야될 과제이다.<br>\n",
    "<br>\n",
    "학습데이터가 있다면 분류모델을 만드는 것을 시도해 볼 수 있으나 실제환경에서는 그러지 못한다.  \n",
    "결국은 클러스터링을 하거나 밀도 추정을 통해서 확률이 낮은 것들을 뽑거나 해야한다.  \n",
    "<br>\n",
    "<br>\n",
    "## 이상징후 관련 알고리즘\n",
    "이상징후감지는 특별히 잘 알려진 알고리즘이 없는 것이 문제이다.  \n",
    "이상징후라는 것으로 정의할 수 있는 것이 매우 다양하고 각 비즈니스별, 정의별 문제와 데이터도 다양하게 다르기 때문이다.  \n",
    "그래도 잘알려진 알고리즘은 LOF(Local Outlier Factor)이며,  \n",
    "그 외 방법은 여러가지 방법으로 패턴을 찾는 것과 관련이 있는 방법들이다.  \n",
    "<br>\n",
    "이상징후에서 말하는 패턴은 매우 광의적인 것으로 정의하기가 모호하지만 세분화하면 다음과 같다.  <br>\n",
    "<br>\n",
    "* 과거에 발생하지 않았던 것인데 최근에 발생한 것들\n",
    "* 확률적으로 매우 드물게 발생한 것들이 갑자기 빈발하게 발생\n",
    "* 논리적으로 함계 발생하기 힘들거나 발생해서는 안되는 어떤 규칙(금지된 행위 또는 물리적으로 발생이 불가능한 사건)이 발생\n",
    "* 일반적인 상황에서 크게 벗어난 예측하지 못한 패턴, 즉 평소의 추이에서 크게 벗어난 극단값\n",
    "  \n",
    "<br>\n",
    "이상징후는 그 특징상 훈련데이터(Training set)확보하기 매우 어렵다.  \n",
    "그렇기 때문에 분류(Classification)알고리즘들을 이상징후에감지에 사용하기 어렵다.  \n",
    "때문에 대부분의 이상징후 감지는 룰 기반(rule based)이거나 군집화 계열, 패턴을 찾아내는 탐색형 알고리즘들이거나 이런 것들을 조합한다.  \n",
    "또한 확률 모델을 사용해 떨어지는 행위들을 이상징후로 판단하기도 한다.  \n",
    "<br>\n",
    "<br>\n",
    "## 이상감지의 실패 원인\n",
    "보통 데이터사이언스 또는 빅데이터에서 이상감지 과제(project)를 실패하는 경우는 초보자들의 흔한 문제로 기계학습으로만 문제를 해결하려는 경향이 크기 때문이다.  \n",
    "\"이상하다\"는 매우 상대적인 개념이며 그 자체로는 정의와 명세가 매우 부족하다는 것을 인식하고 더 구체화 하지 못하면 대부분의 사례에서 문제를 해결 할수 없는 것을 흔히 볼 수 있다. \n",
    "<br><br>\n",
    "## 기계 학습으로 이상감지를 잘 하지 못하는 이유\n",
    "현식적인 기계학습으롤는 이상감지 또는 이상징후 문제를 해결하기 매우 어렵다.  \n",
    "기계학습에 심취한 사람이거나 전공한 사람은 이상징후 감지 문제를 기계학습으로 해결할 수 있다고 주장하거나 맹목적으로 맹신하는 경향이 있다.<br>\n",
    "<br>\n",
    "기계학습으로 이상징후를 감지하기 힘든 이유는 아래와 같다\n",
    "<br>\n",
    "> * 학습데이터가 매우부족\n",
    "> * 이상한 것 같기도 하고 아닌것 같기도 한것들\n",
    "> * 향우 이상한 상황이 발생할지 미래에 대해 지금 알려고하는 것들\n",
    "> * false alarm에 대한 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection 방법\n",
    "ex) 비행기 엔진을 만드는 제조사를 생각해본다.  \n",
    "엔진은 열이 높아짐에 따라서 엔진의 회전이 빨라질 것이라 생각할 수 있다.  \n",
    "아래 그래프의 데이터들과 같이 분포되어 있는 것을 볼 수 있다.  \n",
    "이때 녹색의 x데이터와 같이 다른 데이터들과 밀접한 부분에 존재하는 경우는 정상적인 데이터라고 볼 수 있으나 나홀로 포지션이 위치한 데이터 x는 뭔가 이상한것을 포착할 수 있다.  \n",
    "이 데이터가 anomaly data이다.  \n",
    "![](https://t1.daumcdn.net/cfile/tistory/215FAE4F57B9715033)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m 개의 Dataset이 아래와 같이 있을때 x test데이터가 anomalous인지를 어떻게 판단할까?  \n",
    "바로 p(x)라는 모델을 이용해서 확인을 할 수 있다.  \n",
    "이 함수는 데이터들의 밀도를 이용하는 함수가 될 것이다.(Density estimation)\n",
    "이 p함수는 이 데이터가 정상적인 데이터일 가능성(probability)을 의미한다.  \n",
    "이 함수를 사용해서 데이터를 확인한 결과 값이 어떤 특정한 값($\\varepsilon$)보다 작을 경우에는 이 데이터는 비정상적이다(flag anomaly)라고 판단할 수 있다.  \n",
    "물론 그 반대의 경우에는 정상적인 데이터가 된다.  \n",
    "![](https://t1.daumcdn.net/cfile/tistory/2662A94F57B9715430)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 이상 탐지 알고리즘이 활용되는 분야는 다음과 같다.  \n",
    "- 사기 탐지: 웹사이트의 많은 사용자들 중에서 특별하게 이상한 행동을 취하는 사용자들을 판별하여 문제가 잇는 사용자를 파악한다.  \n",
    "    * 이 때 다양한 Featuers들을 만들 수 있다.(로그인 여부, 위치정보나 행동 패턴이 유사한지, 접속시간 등)\n",
    "    * 만약 이상하다고 판단이 되면 해당 사용자를 block처리 하여 다른 문제가 발생하는 것을 방지 할 수 있다.  \n",
    "- 생산제품 QA: 제조한 물건에 이상 또는 불량 여부를 확인하는데 활용한다.  \n",
    "- 모니터링 : 데이터 센터에 수많은 모니터링하여, 메모리, 디스크, CPU 사용등에 대한 문제가 발생할 소지가 있는 항목들을 모니터링하는데 활용이 가능하다. 특히 아마존 같은 클라우드 서비스에서 사용이 가능하다.<br>\n",
    "<br>\n",
    "![](https://t1.daumcdn.net/cfile/tistory/2565504F57B971582E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian(Normal) Distraibution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가우스 분포또는 정규분포라고도 한다.  \n",
    "어떤 x data에 대해서 이 데이터들이 가우스 분포를 따른다면 평균값잉 되는 $u(\\mu)$와 분산인 $\\sigma^2$로 표현될 수 있다.  \n",
    "여기서$\\sigma$를 standard deviation(표준편차)라고 하고 $\\sigma^2$은 Variance(분산)이라고 한다.  \n",
    "이것을 공식으로 표현하면 다음과 같이 표현이 가능하다.  \n",
    "> ~의 기호는 어떤 분포를 따르고 있다는 것을 의미한다.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> $ X $ ~ $ N(\\mu , \\sigma^2) $ <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것을 그래프로 그리면 하단의 모습과 같이 나타난다.  \n",
    "분포의 중심점이 $\\mu$가 되고 분포의 넓이가 $\\sigma$만큼 넓어지게 된다.  \n",
    "이 것을 수학적으로 표현을 하면 $$p(x: \\mu, \\sigma^2)$$\n",
    "의 공식과 같이 연산이 가능하다.  \n",
    "이 것은 가우스 분포의 곡선을 나타내는 함수가 된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://t1.daumcdn.net/cfile/tistory/2645DB4457B9798B22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### exp (지수) 계산법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$exp(x) = e^x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두가지 변수가 변할 때 분포도가 어떻게 변화하는지 알아본다.  \n",
    "아래 그림의 4가지의 경우와 같이 $\\mu$의 값을 중심축으로 하여 분포 그래프가 만들어지고 $\\sigma$의 값의 크기에 따라 분포도의 넓이가 커지거나 작아지거나 하는 것을 알 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://t1.daumcdn.net/cfile/tistory/2345A74457B9798F22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x벡터의 데이터들로 부터 가우스 분포를 찾아낼 수 도 있다.   \n",
    "x벡터가 하나의 축에 나열되어 있다고 생각해본다. (아래 그림 참조)  \n",
    "그러면 파란색 분포 그래프와 같이 분포를 보일것이다. 라고 추정이 가능하다.  \n",
    "더 정확히는 하단의 공식으로 부터 두 변수인 $\\mu$와 $\\sigma$의 값을 찾을 수도 있다.  \n",
    "$\\sigma$는 각 데이터들이 중심점과의 거리 제곱에 대한 평균 값이 된다.(아래 그림의 오른쪽 파란색 공식)  \n",
    "이때 $m$으로 나누는것이 일반적이기는 하지만 때에 따라 $m-1$값으로 나누는 경우도 존재한다.  \n",
    "두가지의 차이가 크게 없으니 둘중 하나로 사용한다는 것을 알고 있으면 된다.\n",
    "![](https://t1.daumcdn.net/cfile/tistory/2329AA4457B9799337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "x 벡터에 대한 training set이 있다고 가정한다.  \n",
    "x 벡터가 가지고 있는 n개의 features에 대하여 각 feature 마다 고유한 분포를 이루고 있을 것이다.  \n",
    "이 모든 features의 가우스 분포를 곱하면 p(x)가 된다.  \n",
    "아래 그림의 분홍색 박스안에 공식과 같이 표현된다.  \n",
    "![](https://t1.daumcdn.net/cfile/tistory/277C054157B9822C07)  \n",
    "Summation은 모든 값의 합을 의미하는 기호이며,  \n",
    "PI($\\Pi$)는 모든 값의 곱을 의미하는 기호이다.  \n",
    "그러므로 j번째 feature에 대한 p함수들의 곱이 된다.  \n",
    "이렇게 어떤 분포를 형성하는 것을 Density estimation이라고 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection algorithm이 동작하는 방식\n",
    "먼저 x features중에서 특이하게 값이 크거나 작거나 하여 이상이 생길 만한 feature를 선택한다.  \n",
    "또는 어느 feature가 일반적인 속성을 가지고 있어 분포를 보일 가능성이 있는 것을 선택한다.   \n",
    "그리고 각 feature 마다 가우스 분포를 이루는 parameter인 $\\mu$와 $\\sigma$의 값을 찾는다.  \n",
    "아래 그림의 2번 공식과 같이 벡터 연산을 통하여 구할 수 있다.  \n",
    "![](https://t1.daumcdn.net/cfile/tistory/2274FB4157B982300E)\n",
    "마지막으로 p(x)의 함수를 $\\Pi$공식을 이용하여 구한다.  \n",
    "그리고 이값이 특정 값($\\varepsilon$)값과 비교하여 작을 경우에는 anomaly로 판단할 수 있다.  \n",
    "결과 값이 아주 작은 값이 된다는 것은 이 데이터가 정상 데이터일 가능성이 매우 낮다는 의미가 되기 때문이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림은 예제를 들어 설명하는 내용이다.  \n",
    "![](https://t1.daumcdn.net/cfile/tistory/23578A4157B9823431)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1$, $x_2$의 데이터가 그래프와 같이 존재할때,  \n",
    "각각의 $x_1$의 feature가 나타내는 가우시안 분포는 오른쪽 위의 그래프와 같이 넓직한 그래프의 분포를 이루고 있다.  \n",
    "또 $x_2$ of feature가 나타내는 가우시안 분포를 구해보니 3, 1의 값을 가지고 있는 가우스 분포를 오른쪽아래 그래프와 같이 뾰족하게 표현하고 있다.  \n",
    "이때 녹색의 두개 x를 샘플링하여 test를 해보려 한다.  \n",
    "* x test(1)은 분포 내에 존재하고 있어 $p(x test(1))$값이 0.0426으로 $\\varepsilon$ = 0.02보다 큰 값이므로 정상 데이터라 판단 할 수 있다.  \n",
    "* x test(2)은 분포 밖에 존재하고 있어 $p(x test(2))$값이 0.0021으로 $\\varepsilon$ = 0.02보다 작은 값을 가지고 있으므로 Anomaly데이터라고 판단기 가능하다.  \n",
    "  \n",
    "이 두가지 features가 나타내는 p(x)를 3차원 그래프로 나타내면 위의 그림과 같이 나타난다.  \n",
    "위 p(x)는 $x_1$, $x_2$가 각각 값을 가지고 있을 때 높이 값을 의미한다.  \n",
    "즉, p(x)는 분포 그래프 표면의 높이가 되는것이다.  \n",
    "\n",
    "아래의 그림의 빗금은 분포 밖에 위치하는 데이터들이 있다면 anomaly로 판단이 가능하게 되는것이다.  \n",
    "![](https://t1.daumcdn.net/cfile/tistory/2579334157B982380A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filePath, delimiter=','):\n",
    "    return genfromtxt(filePath, delimiter=delimiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anomaly detection 다른 알고리즘\n",
    "## 적용방안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
